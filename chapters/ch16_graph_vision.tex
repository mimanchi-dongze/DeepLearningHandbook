\chapter{图网络与空间视觉}
\label{ch:graph_vision}

超越传统的网格数据（像素），神经网络能够处理非欧几里得空间（图）或以全新视角审视视觉（Patch）。

\begin{notation}
\begin{itemize}
    \item $x$: Input tensor
    \item $W$: Weight matrix
    \item $\sigma$: Activation function
    \item $\mathbf{x}$: Input vector
\end{itemize}
\end{notation}

\mnote{$x$: Input tensor \\ $W$: Weight matrix \\ $\sigma$: Activation function \\ $\mathbf{x}$: Input vector}
\section{图卷积网络 (GCN)}
在图数据上进行信息传递（Message Passing），节点特征通过邻接矩阵进行聚合。

\begin{rosetta}{GCN 谱图聚合规则}
    \begin{equation}
        H^{(l+1)} = \sigma\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} W^{(l)}\right)
    \end{equation}
    其中：
    \begin{itemize}
        \item $\tilde{A} = A + I_N$ 是带有自环的邻接矩阵（即每个节点也看自己）。
        \item $\tilde{D}$ 是 $\tilde{A}$ 的度矩阵（对角阵，用于归一化，防止度大的节点梯度爆炸）。
        \item $H^{(l)}$ 是第 $l$ 层的节点特征矩阵。
    \end{itemize}
\end{rosetta}

\section{视觉 Transformer (ViT)}
将图像视为序列 (Sequence of Patches)，彻底打破了 CNN 的归纳偏置。

\begin{rosetta}{ViT Patch 嵌入}
    一张 $H \times W \times C$ 的图像被切割为 $N$ 个大小为 $P \times P$ 的图像块。
    \begin{equation}
        N = \frac{H \times W}{P^2}
    \end{equation}
    \textbf{数学展开}:
    \begin{equation}
        \mathbf{z}_0 = [x_{\text{class}}; \, \mathbf{x}_p^1\mathbf{E}; \, \dots; \, \mathbf{x}_p^N\mathbf{E}] + \mathbf{E}_{pos}
    \end{equation}
    其中 $\mathbf{x}_p^i$ 是展平的图像块，$\mathbf{E}$ 是线性投影矩阵，$\mathbf{E}_{pos} \in \mathbb{R}^{(N+1) \times D}$ 是可学习的 1D 位置编码，$x_{\text{class}}$ 是用于分类的全局 Token。
\end{rosetta}
